{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de errores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Con la clase creada en el módulo 8, tener en cuenta diferentes casos en que el código pudiera arrojar error. Por ejemplo, en la creación del objeto recibimos una lista de números enteros pero ¿qué pasa si se envía otro tipo de dato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'/C:/Users/lopez/Documents/Henry/Repos/Python-Prep/07 - Classes & OOP/herramientas.py') # Agrega la ruta al archivo 'herramientas.py' al sys.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import herramientas as h  #se importa el módulo llamado 'herramientas' y se le asigna un alias 'h' utilizando la palabra clave as. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h1 \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39;49mHerramientas(\u001b[39m'\u001b[39;49m\u001b[39mhola\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m#si se envia un tipo de dato diferente al esperado, arroja error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\SoyHenry-DataScince\\Python-Prep\\M09_errorhandling\\herramientas.py:5\u001b[0m, in \u001b[0;36mHerramientas.__init__\u001b[1;34m(self, lista_numeros)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mtype\u001b[39m(lista_numeros) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSe ha creado una lista vacía. Se esperaba una lista de núemeros enteros\u001b[39m\u001b[39m'\u001b[39m)  \n\u001b[0;32m      6\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m lista_numeros\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros"
     ]
    }
   ],
   "source": [
    "h1 = h.Herramientas('hola') #si se envia un tipo de dato diferente al esperado, arroja error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = h.Herramientas([2,3,5,6,2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) En la función que hace la conversión de grados, validar que los parámetros enviados sean los esperados, de no serlo, informar cuáles son los valores esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\Usuario\\\\Documents\\\\SoyHenry-DataScince\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib  #se importa el módulo importlib, el cual proporciona funciones para recargar (reload) módulos previamente importados. \n",
    "importlib.reload(h)  # la función reload() de importlib recargar el módulo herramientas (previamente importado y asignado a un alias h)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = h.Herramientas([2,3,5,6,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los parametros esperados son: ['celsius', 'kelvin', 'farenheit']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.conversion_grados(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35.6, 37.4, 41.0, 42.8, 35.6]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.conversion_grados('celsius','farenheit')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Importar el modulo \"unittest\" y crear los siguientes casos de pruebas sobre la clase utilizada en el punto 2<br>\n",
    "Creacion del objeto incorrecta<br>\n",
    "Creacion correcta del objeto<br>\n",
    "Metodo valor_modal()<br>\n",
    "\n",
    "Se puede usar \"raise ValueError()\" en la creación de la clase para verificar el error. Investigar sobre esta funcionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest #se importa el módulo unittest,es un marco de trabajo integrado en Python para escribir y ejecutar pruebas unitarias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase(unittest.TestCase):\n",
    "    \n",
    "    def test_crear_objeto1(self):\n",
    "        param = 'hola'\n",
    "        self.assertRaises(ValueError, h.Herramientas, param)\n",
    "        #self.failUnlessRaises(ValueError, h.Herramientas, param)\n",
    "\n",
    "    def test_crear_objeto2(self):\n",
    "        param = [1,2,2,5]\n",
    "        h1 = h.Herramientas(param)\n",
    "        self.assertEqual(h1.lista, param)\n",
    "\n",
    "    def test_valor_modal(self):\n",
    "        lis = [1,2,1,3]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        moda, veces = h1.valor_modal(False)\n",
    "        moda = [moda]\n",
    "        moda.append(veces)\n",
    "        resultado = [1, 2]\n",
    "        self.assertEqual(moda, resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comentado paso a paso\n",
    "class ProbandoMiClase(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    Clase de prueba para la clase Herramientas del módulo 'h'.\n",
    "    Esta clase hereda de unittest.TestCase, lo que la convierte en una clase de prueba.\n",
    "    \"\"\"\n",
    "\n",
    "    def test_crear_objeto1(self):\n",
    "        \"\"\"\n",
    "        Método de prueba para verificar el comportamiento al crear un objeto Herramientas con un parámetro inválido.\n",
    "        \"\"\"\n",
    "        param = 'hola'\n",
    "        self.assertRaises(ValueError, h.Herramientas, param)\n",
    "        # self.failUnlessRaises(ValueError, h.Herramientas, param)\n",
    "        # Se utiliza assertRaises para verificar que al crear un objeto Herramientas con un parámetro inválido\n",
    "        # se genere una excepción de tipo ValueError. Se espera que el código en el bloque de prueba genere esta excepción.\n",
    "        # Si no se genera la excepción, el caso de prueba falla.\n",
    "\n",
    "    def test_crear_objeto2(self):\n",
    "        \"\"\"\n",
    "        Método de prueba para verificar el comportamiento al crear un objeto Herramientas con una lista válida como parámetro.\n",
    "        \"\"\"\n",
    "        param = [1, 2, 2, 5]\n",
    "        h1 = h.Herramientas(param)\n",
    "        self.assertEqual(h1.lista, param)\n",
    "        # Se utiliza assertEqual para verificar que la lista almacenada en el objeto h1 de tipo Herramientas\n",
    "        # sea igual a la lista param proporcionada como parámetro al crear el objeto.\n",
    "        # Si las listas no son iguales, el caso de prueba falla.\n",
    "\n",
    "    def test_valor_modal(self):\n",
    "        \"\"\"\n",
    "        Método de prueba para verificar el comportamiento del método valor_modal de la clase Herramientas.\n",
    "        \"\"\"\n",
    "        lis = [1, 2, 1, 3]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        moda, veces = h1.valor_modal(False)\n",
    "        moda = [moda]\n",
    "        moda.append(veces)\n",
    "        resultado = [1, 2]\n",
    "        self.assertEqual(moda, resultado)\n",
    "        # Se utiliza assertEqual para verificar que el valor de moda y la cantidad de repeticiones devueltos\n",
    "        # por el método valor_modal de la clase Herramientas sean iguales a los valores esperados almacenados en resultado.\n",
    "        # Si los valores no coinciden, el caso de prueba falla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase.test_valor_modal) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x28082cd4f50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Probar una creación incorrecta y visualizar la salida del \"raise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado con un elemento 0. Se esperaba una lista de núemeros enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4832/323435116.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHerramientas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'algo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\lopez\\Documents\\Henry\\Repos\\Python-Prep\\08 - Error Handling\\herramientas.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, lista_numeros)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlista_numeros\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlista\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Se ha creado con un elemento 0. Se esperaba una lista de núemeros enteros'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlista\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlista_numeros\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado con un elemento 0. Se esperaba una lista de núemeros enteros"
     ]
    }
   ],
   "source": [
    "h2 = h.Herramientas('algo')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Agregar casos de pruebas para el método verifica_primos() realizando el cambio en la clase, para que devuelva una lista de True o False en función de que el elemento en la posisicón sea o no primo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase2(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_primos1(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        primos = h1.verifica_primo()\n",
    "        primos_esperado = [True, True, False, False, True]\n",
    "        self.assertEqual(primos, primos_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\lopez\\\\Documents\\\\Henry\\\\Repos\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase) ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.006s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2654fadf070>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Agregar casos de pruebas para el método conversion_grados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase3(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_conversion1(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        grados = h1.conversion_grados('celsius','farenheit')\n",
    "        grados_esperado = [35.6, 37.4, 46.4, 50.0, 55.4]\n",
    "        self.assertEqual(grados, grados_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\lopez\\\\Documents\\\\Henry\\\\Repos\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase) ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2) ... ok\n",
      "test_verifica_conversion1 (__main__.ProbandoMiClase3) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2654fadf850>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Agregar casos de pruebas para el método factorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase4(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_factorial(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        factorial = h1.factorial()\n",
    "        factorial_esperado = [2, 6, 40320, 3628800, 6227020800]\n",
    "        self.assertEqual(factorial, factorial_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\lopez\\\\Documents\\\\Henry\\\\Repos\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase) ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2) ... ok\n",
      "test_verifica_conversion1 (__main__.ProbandoMiClase3) ... ok\n",
      "test_verifica_factorial (__main__.ProbandoMiClase4) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2654faf5730>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c85384e4cb51c8b72350f3a8712cc8351fdc3955e32a27f9b60c6242ab125f01"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
